# Machine Reading Comprehension and Question Answering

## Theses
- [2018 Stanford University] **Neural Reading Comprehension and Beyond**, [[thesis]](https://cs.stanford.edu/~danqi/papers/thesis.pdf), [[copy]](/Documents/Theses/Neural%20Reading%20Comprehension%20and%20Beyond.pdf), [[bibtex]](/Bibtex/Neural%20Reading%20Comprehension%20and%20Beyond.bib), author: [[Danqi Chen]](https://cs.stanford.edu/~danqi/).

## Datasets
- [2013 EMNLP] **MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text**, [[paper]](http://aclweb.org/anthology/D13-1020), [[bibtex]](/Bibtex/MCTest%20-%20A%20Challenge%20Dataset%20for%20the%20Open-Domain%20Machine%20Comprehension%20of%20Text.bib), [[homepage]](https://mattr1.github.io/mctest/), source: [[mcobzarenco/mctest]](https://github.com/mcobzarenco/mctest).
- [2015 NIPS] **CNN/DailyMail: Teaching Machines to Read and Comprehend**, [[paper]](https://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf), [[bibtex]](/Bibtex/CNN-DailyMail%20-%20Teaching%20Machines%20to%20Read%20and%20Comprehend.bib), [[homepage]](https://cs.nyu.edu/~kcho/DMQA/), sources: [[thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend]](https://github.com/thomasmesnard/DeepMind-Teaching-Machines-to-Read-and-Comprehend).
- [2016 EMNLP] **SQuAD 100,000+ Questions for Machine Comprehension of Text**, [[paper]](http://aclweb.org/anthology/D16-1264), [[bibtex]](/Bibtex/SQuAD%20Questions%20for%20Machine%20Comprehension%20of%20Text.bib), [[homepage]](https://rajpurkar.github.io/SQuAD-explorer/).
- [2016 ICLR] **bAbI: Towards AI-Complete Question Answering: a Set of Prerequisite Toy Tasks**, [[paper]](https://arxiv.org/pdf/1502.05698.pdf), [[bibtex]](Towards%20AI-Complete%20Question%20Answering%20-%20a%20Set%20of%20Prerequisite%20Toy%20Tasks.bib), [[homepage]](https://research.fb.com/downloads/babi/), sources: [[facebook/bAbI-tasks]](https://github.com/facebook/bAbI-tasks).
- [2017 EMNLP] **World Knowledge for Reading Comprehension: Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions**, [[paper]](http://aclweb.org/anthology/D17-1086), [[bibtex]](/Bibtex/Rare%20Entity%20Prediction%20with%20Hierarchical%20LSTMs%20Using%20External%20Descriptions.bib), [[homepage]](http://dataset.cs.mcgill.ca/downloads/rare_entity_dataset.html).
- [2017 EMNLP] **RACE: Large-scale ReAding Comprehension Dataset From Examinations**, [[paper]](http://aclweb.org/anthology/D17-1082), [[bibtex]](RACE%20-%20Large-scale%20ReAding%20Comprehension%20Dataset%20From%20Examinations.bib), [[homepage]](http://www.cs.cmu.edu/~glai1/data/race/), sources: [[qizhex/RACE_AR_baselines]](https://github.com/qizhex/RACE_AR_baselines).
- [2017 ACL] **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension**, [[paper]](http://aclweb.org/anthology/P17-1147), [[bibtex]](/Bibtex/TriviaQA%20-%20A%20Large%20Scale%20Distantly%20Supervised%20Challenge%20Dataset%20for%20Reading%20Comprehension.bib) [[homepage]](http://nlp.cs.washington.edu/triviaqa/), sources: [[mandarjoshi90/triviaqa]](https://github.com/mandarjoshi90/triviaqa).
- [2018 TACL] **QAngaroo: Constructing Datasets for Multi-hop Reading Comprehension Across Documents**, [[paper]](http://aclweb.org/anthology/Q18-1021), [[bibtex]](/Bibtex/Constructing%20Datasets%20for%20Multi-hop%20Reading%20Comprehension%20Across%20Documents.bib), [[homepage]](http://qangaroo.cs.ucl.ac.uk).
- [2018 ACL] **Know What You Donâ€™t Know: Unanswerable Questions for SQuAD**, [[paper]](https://www.aclweb.org/anthology/P18-2124.pdf), [[bibtex]](/Bibtex/Know%20What%20You%20Dont%20Know%20-%20Unanswerable%20Questions%20for%20SQuAD.bib), [[supplementary]](https://www.aclweb.org/anthology/attachments/P18-2124.Notes.pdf), [[homepage]](https://rajpurkar.github.io/SQuAD-explorer/), sources: [[CodaLab Worksheet]](https://worksheets.codalab.org/worksheets/0x9a15a170809f4e2cb7940e1f256dee55/).
- [2018 ICLR] **CLOTH: Large-scale Cloze Test Dataset Designed by Teachers**, [[paper]](https://arxiv.org/pdf/1711.03225.pdf), [[bibtex]](/Bibtex/Large-scale%20Cloze%20Test%20Dataset%20Designed%20by%20Teachers.bib), [[homepage]](http://www.qizhexie.com), sources: [[qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers]](https://github.com/qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers).
- [2018 NAACL] **MultiRC: Looking Beyond the Surface - A Challenge Set for Reading Comprehension over Multiple Sentences**, [[paper]](http://aclweb.org/anthology/N18-1023), [[bibtex]](/Bibtex/Looking%20Beyond%20the%20Surface%20-%20A%20Challenge%20Set%20for%20Reading%20Comprehension%20over%20Multiple%20Sentences.bib), [[homepage]](http://cogcomp.org/multirc/), sources: [[CogComp/multirc]](https://github.com/CogComp/multirc/).
- [2018 EMNLP] **HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering**, [[paper]](http://aclweb.org/anthology/D18-1259), [[bibtex]](/Bibtex/HotpotQA%20-%20A%20Dataset%20for%20Diverse%20Explainable%20Multi-hop%20Question%20Answering.bib), [[attachment]](http://anthology.aclweb.org/attachments/D/D18/D18-1259.Attachment.pdf), [[homepage]](https://hotpotqa.github.io), sources: [[hotpotqa/hotpot]](https://github.com/hotpotqa/hotpot).
- [2019 NAACL] **CommonsenseQA: A Question Answering Challenge Targeting**, [[paper]](https://arxiv.org/pdf/1811.00937.pdf), [[bibtex]](/Bibtex/CommonsenseQA.md), [[homepage]](https://www.tau-nlp.org/commonsenseqa), sources: [[jonathanherzig/commonsenseqa]](https://github.com/jonathanherzig/commonsenseqa).
- [2019 EMNLP] **COSMOS QA: Machine Reading Comprehension with Contextual Commonsense Reasoning**, [[paper]](https://www.aclweb.org/anthology/D19-1243.pdf), [[bibtex]](/Bibtex/COSMOS%20QA%20-%20Machine%20Reading%20Comprehension%20with%20Contextual%20Commonsense%20Reasoning.bib), [[homepage]](https://wilburone.github.io/cosmos/).
- [2020 ICLR] **ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning**, [[paper]](https://openreview.net/pdf?id=HJgJtT4tvB), [[bibtex]](/Bibtex/ReClor%20-%20A%20Reading%20Comprehension%20Dataset%20Requiring%20Logical%20Reasoning.bib), [[homepage]](http://whyu.me/reclor/), sources: [[yuweihao/reclor]](https://github.com/yuweihao/reclor).

## Papers
- [2014 NIPS] **Deep Learning for Answer Sentence Selection**, [[paper]](https://arxiv.org/pdf/1412.1632.pdf), sources: [[brmson/Sentence-selection]](https://github.com/brmson/Sentence-selection).
- [2014 ACL] **Freebase QA: Information Extraction or Semantic Parsing?**, [[paper]](http://aclweb.org/anthology/W14-2416).
- [2015 IJCAI] **Convolutional Neural Tensor Network Architecture for Community-based Question Answering**, [[paper]](https://www.ijcai.org/Proceedings/15/Papers/188.pdf), [[bibtex]](/Bibtex/Convolutional%20Neural%20Tensor%20Network%20Architecture%20for%20Community-based%20Question%20Answering.bib), sources: [[GauravBh1010tt/DeepLearn]](https://github.com/GauravBh1010tt/DeepLearn/tree/master/convolution%20neural%20tensor%20network), [[SongRb/Seq2SeqLearning]](https://github.com/SongRb/Seq2SeqLearning).
- [2015 NIPS] **Pointer Networks**, [[paper]](https://arxiv.org/pdf/1506.03134.pdf), [[blog]](http://fastml.com/introduction-to-pointer-networks/), sources: [[devsisters/pointer-network-tensorflow]](https://github.com/devsisters/pointer-network-tensorflow), [[https://github.com/ikostrikov/TensorFlow-Pointer-Networks]](https://github.com/ikostrikov/TensorFlow-Pointer-Networks), [[keon/pointer-networks]](https://github.com/keon/pointer-networks), [[pemami4911/neural-combinatorial-rl-pytorch]](https://github.com/pemami4911/neural-combinatorial-rl-pytorch), [[shiretzet/PointerNet]](https://github.com/shiretzet/PointerNet).
- [2016 ACL] **Question Answering on Freebase via Relation Extraction and Textual Evidence**, [[paper]](http://www.aclweb.org/anthology/P16-1220), sources: [[syxu828/QuestionAnsweringOverFB]](https://github.com/syxu828/QuestionAnsweringOverFB).
- [2016 EMNLP] **Long Short-Term Memory-Networks for Machine Reading**, [[paper]](https://arxiv.org/pdf/1601.06733.pdf), sources: [[cheng6076/SNLI-attention]](https://github.com/cheng6076/SNLI-attention), [[vsitzmann/snli-attention-tensorflow]](https://github.com/vsitzmann/snli-attention-tensorflow).
- [2016 ICLR] **LSTM-based Deep Learning Models for Non-factoid Answer Selection**, [[paper]](https://arxiv.org/pdf/1511.04108.pdf), sources: [[Alan-Lee123/answer-selection]](https://github.com/Alan-Lee123/answer-selection), [[tambetm/allenAI]](https://github.com/tambetm/allenAI).
- [2016 ICML] **Ask Me Anything: Dynamic Memory Networks for Natural Language Processing**, [[paper]](https://arxiv.org/pdf/1506.07285.pdf), sources: [[DongjunLee/dmn-tensorflow]](https://github.com/DongjunLee/dmn-tensorflow).
- [2016 ACL] **A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task**, [[paper]](https://arxiv.org/pdf/1606.02858.pdf), sources: [[danqi/rc-cnn-dailymail]](https://github.com/danqi/rc-cnn-dailymail).
- [2016 ICML] **Dynamic Memory Networks for Visual and Textual Question Answering**, [[paper]](https://arxiv.org/pdf/1603.01417.pdf), [[blog]](https://yerevann.github.io/2016/02/05/implementing-dynamic-memory-networks/), sources: [[therne/dmn-tensorflow]](https://github.com/therne/dmn-tensorflow), [[barronalex/Dynamic-Memory-Networks-in-TensorFlow]](https://github.com/barronalex/Dynamic-Memory-Networks-in-TensorFlow), [[ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus]](https://github.com/ethancaballero/Improved-Dynamic-Memory-Networks-DMN-plus), [[dandelin/Dynamic-memory-networks-plus-Pytorch]](https://github.com/dandelin/Dynamic-memory-networks-plus-Pytorch), [[DeepRNN/visual_question_answering]](https://github.com/DeepRNN/visual_question_answering).
- [2017 ICLR] **Query-Reduction Networks for Question Answering**, [[paper]](https://arxiv.org/pdf/1606.04582.pdf), [[homepage]](http://uwnlp.github.io/qrn/), sources: [[uwnlp/qrn]](https://github.com/uwnlp/qrn).
- [2017 ICLR] **Bi-Directional Attention Flow for Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1611.01603.pdf), [[homepage]](https://allenai.github.io/bi-att-flow/), [[demo]](http://allgood.cs.washington.edu:1995), sources: [[allenai/bi-att-flow]](https://github.com/allenai/bi-att-flow).
- [2017 KDD] **ReasoNet: Learning to Stop Reading in Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1609.05284.pdf), [[bibtex]](/Bibtex/ReasoNet%20-%20Learning%20to%20Stop%20Reading%20in%20Machine%20Comprehension.bib), source: [[CNTK/Tutorials/CNTK_302_ReasoNet]](https://github.com/Microsoft/CNTK/blob/penhe/reasonet_tutorial/Tutorials/CNTK_302_ReasoNet.ipynb).
- [2017 ACL] **Learning to Skim Text**, [[paper]](http://aclweb.org/anthology/P17-1172), [[notes]](https://zhuanlan.zhihu.com/p/30555359).
- [2017 ACL] **R-Net: Machine Reading Comprehension with Self-matching Networks**, [[paper]](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf), [[blog]](http://yerevann.github.io/2017/08/25/challenges-of-reproducing-r-net-neural-network-using-keras/), sources: [[HKUST-KnowComp/R-Net]](https://github.com/HKUST-KnowComp/R-Net), [[YerevaNN/R-NET-in-Keras]](https://github.com/YerevaNN/R-NET-in-Keras), [[minsangkim142/R-net]](https://github.com/minsangkim142/R-net).
- [2017 ICLR] **Machine Comprehension Using Match-LSTM and Answer Pointer**, [[paper]](https://arxiv.org/pdf/1608.07905.pdf), sources: [[shuohangwang/SeqMatchSeq]](https://github.com/shuohangwang/SeqMatchSeq), [[MurtyShikhar/Question-Answering]](https://github.com/MurtyShikhar/Question-Answering), [[InnerPeace-Wu/reading_comprehension-cs224n]](https://github.com/InnerPeace-Wu/reading_comprehension-cs224n).
- [2017 EMNLP] **Accurate Supervised and Semi-Supervised Machine Reading for Long Documents**, [[paper]](http://aclweb.org/anthology/D17-1214), [[bibtex]](/Bibtex/Accurate%20Supervised%20and%20Semi-Supervised%20Machine%20Reading%20for%20Long%20Documents.bib).
- [2017 CoNLL] **Making Neural QA as Simple as Possible but not Simpler**, [[paper]](https://arxiv.org/pdf/1703.04816.pdf), [[homepage]](https://dirkweissenborn.github.io/publications.html), [[github-page]](https://github.com/georgwiese), sources: [[georgwiese/biomedical-qa]](https://github.com/georgwiese/biomedical-qa).
- [2017 EMNLP] **Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1706.09789.pdf), sources: [[davidgolub/QuestionGeneration]](https://github.com/davidgolub/QuestionGeneration).
- [2017 ACL] **Attention-over-Attention Neural Networks for Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1607.04423.pdf), sources: [[OlavHN/attention-over-attention]](https://github.com/OlavHN/attention-over-attention), [[marshmelloX/attention-over-attention]](https://github.com/marshmelloX/attention-over-attention).
- [2017 EMNLP] **Identifying Where to Focus in Reading Comprehension for Neural Question Generation**, [[paper]](http://aclweb.org/anthology/D17-1219), [[bibtex]](/Bibtex/Identifying%20Where%20to%20Focus%20in%20Reading%20Comprehension%20for%20Neural%20Question%20Generation.bib).
- [2017 ACL] **Improved Neural Relation Detection for Knowledge Base Question Answering**, [[paper]](https://arxiv.org/pdf/1704.06194.pdf).
- [2017 ACL] **An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge**, [[paper]](https://arxiv.org/pdf/1606.00979.pdf), [[homepage]](http://www.nlpr.ia.ac.cn/cip/~liukang/index.html), [[blog]](http://blog.csdn.net/LAW_130625/article/details/78484866).
- [2017 EMNLP] **Learning what to read: Focused machine reading**, [[paper]](http://aclweb.org/anthology/D17-1313), [[bibtex]](/Bibtex/Learning%20what%20to%20read%20-%20Focused%20machine%20reading.bib).
- [2017 ACL] **Reading Wikipedia to Answer Open-Domain Questions**, [[paper]](https://arxiv.org/pdf/1704.00051.pdf), sources: [[facebookresearch/DrQA]](https://github.com/facebookresearch/DrQA), [[hitvoice/DrQA]](https://github.com/hitvoice/DrQA).
- [2017 CoNLL] **Zero-Shot Relation Extraction via Reading Comprehension**, [[paper]](https://www.aclweb.org/anthology/K17-1034.pdf), [[bibtex]](https://www.aclweb.org/anthology/K17-1034.bib), sources: [[omerlevy/bidaf_no_answer]](https://bitbucket.org/omerlevy/bidaf_no_answer/src/default/), [[zhuzhicai/SQuAD2.0-Baseline-Test-with-BiDAF-No-Answer]](https://github.com/zhuzhicai/SQuAD2.0-Baseline-Test-with-BiDAF-No-Answer).
- [2017 AAAI] **Cross Temporal Recurrent Networks for Ranking Question Answer Pairs**, [[paper]](https://oar.a-star.edu.sg/jspui/bitstream/123456789/2406/3/16632-76869-1-PB.pdf), [[bibtex]](/Bibtex/Cross%20Temporal%20Recurrent%20Networks%20for%20Ranking%20Question%20Answer%20Pairs.bib).
- [2018 ICLR] **MaskGAN: Better Text Generation via Filling in the `______`**, [[paper]](https://arxiv.org/pdf/1801.07736.pdf).
- [2018 AAAI] **Multi-attention Recurrent Network for Human Communication Comprehension**, [[paper]](https://arxiv.org/pdf/1802.00923.pdf).
- [2018 IEEE Access] **An Attention-Based Word-Level Interaction Model for Knowledge Base Relation Detection**, [[paper]](https://arxiv.org/pdf/1801.09893.pdf), [[bibtex]](/Bibtex/An%20Attention-Based%20Word-Level%20Interaction%20Model%20for%20Knowledge%20Base%20Relation%20Detection.bib).
- [2018 ICLR] **FusionNet: Fusing via Fully-aware Attention with Application to Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1711.07341.pdf), sources: [[exe1023/FusionNet]](https://github.com/exe1023/FusionNet), [[momohuang/FusionNet-NLI]](https://github.com/momohuang/FusionNet-NLI).
- [2018 NAACL] **Contextualized Word Representations for Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1712.03609.pdf), sources: [[shimisalant/CWR]](https://github.com/shimisalant/CWR).
- [2018 ICLR] **QANet: Combing Local Convolution with Global Self-Attention for Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1804.09541.pdf), sources: [[hengruo/QANet-pytorch]](https://github.com/hengruo/QANet-pytorch), [[NLPLearn/QANet]](https://github.com/NLPLearn/QANet).
- [2018 ICLR] **Neural Speed Reading via Skim-RNN**, [[paper]](https://arxiv.org/pdf/1711.02085.pdf), sources: [[schelotto/Neural_Speed_Reading_via_Skim-RNN_PyTorch]](https://github.com/schelotto/Neural_Speed_Reading_via_Skim-RNN_PyTorch).
- [2018 SemEval] **Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension**, [[paper]](https://arxiv.org/pdf/1803.00191.pdf), sources: [[intfloat/commonsense-rc]](https://github.com/intfloat/commonsense-rc).
- [2018 ACL] **Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge**, [[paper]](https://arxiv.org/pdf/1805.07858.pdf).
- [2018 ACL] **Stochastic Answer Networks for Machine Reading Comprehension**, [[paper]](http://aclweb.org/anthology/P18-1157), [[bibtex]](/Bibtex/Stochastic%20Answer%20Networks%20for%20Machine%20Reading%20Comprehension.bib), sources: [[kevinduh/san_mrc]](https://github.com/kevinduh/san_mrc).
- [2018 EMNLP] **Commonsense for Generative Multi-Hop Question Answering Tasks**, [[paper]](https://aclweb.org/anthology/D18-1454), [[bibtex]](/Bibtex/Commonsense%20for%20Generative%20Multi-Hop%20Question%20Answering%20Tasks.bib), sources: [[yicheng-w/CommonSenseMultiHopQA]](https://github.com/yicheng-w/CommonSenseMultiHopQA).
- [2018 NIPS] **Densely Connected Attention Propagation for Reading Comprehension**, [[paper]](https://papers.nips.cc/paper/7739-densely-connected-attention-propagation-for-reading-comprehension.pdf), [[bibtex]](/Bibtex/Densely%20Connected%20Attention%20Propagation%20for%20Reading%20Comprehension.bib), sources: [[vanzytay/NIPS2018_DECAPROP]](https://github.com/vanzytay/NIPS2018_DECAPROP).
- [2018 ArXiv] **Weaver: Deep Co-Encoding of Questions and Documents for Machine Reading**, [[paper]](https://arxiv.org/pdf/1804.10490.pdf), [[bibtex]](/Bibtex/Weaver%20-%20Deep%20Co-Encoding%20of%20Questions%20and%20Documents%20for%20Machine%20Reading.bib).
- [2018 ArXiv] **U-Net: Machine Reading Comprehension with Unanswerable Questions**, [[paper]](https://arxiv.org/pdf/1810.06638.pdf), [[bibtex]](https://scholar.googleusercontent.com/scholar.bib?q=info:Zey7kpVVZ6AJ:scholar.google.com/&output=citation&scisdr=CgU1_ws_EMa_0lNZcjM:AAGBfm0AAAAAXqZcajPpD2F-yhVrMptc_v-pLhzulSJ6&scisig=AAGBfm0AAAAAXqZcahkFoMcAuW-4jlvvqr8T5l3JNU_Q&scisf=4&ct=citation&cd=-1&hl=en), sources: [[FudanNLP/UNet]](https://github.com/FudanNLP/UNet).
- [2018 KDD] **Multi-Cast Attention Networks for Retrieval-based Question Answering and Response Prediction**, [[paper]](https://arxiv.org/pdf/1806.00778.pdf), [[bibtex]](/Bibtex/Multi-Cast%20Attention%20Networks%20for%20Retrieval-based%20Question%20Answering%20and%20Response%20Prediction.bib).
- [2018 ACL] **Simple and Effective Multi-Paragraph Reading Comprehension**, [[paper]](https://www.aclweb.org/anthology/P18-1078), [[bibtex]](/Bibtex/Simple%20and%20Effective%20Multi-Paragraph%20Reading%20Comprehension.bib), sources: [[allenai/document-qa]](https://github.com/allenai/document-qa).
- [2018 AAAI] **Reinforced Ranker-Reader for Open-Domain Question Answering**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16712/16165), [[bibtex]](/Bibtex/Reinforced%20Ranker-Reader%20for%20Open-Domain%20Question%20Answering.bib), sources: [[shuohangwang/mprc]](https://github.com/shuohangwang/mprc).
- [2018 ICLR] **Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering**, [[paper]](https://openreview.net/pdf?id=rJl3yM-Ab), [[bibtex]](/Bibtex/Evidence%20Aggregation%20for%20Answer%20Re-Ranking%20in%20Open-Domain%20Question%20Answering.bib), sources: [[shuohangwang/mprc]](https://github.com/shuohangwang/mprc).
- [2018 NAACL] **The Web as a Knowledge-base for Answering Complex Questions**, [[paper]](https://www.aclweb.org/anthology/N18-1059), [[bibtex]](/Bibtex/The%20Web%20as%20a%20Knowledge-base%20for%20Answering%20Complex%20Questions.bib).
- [2018 EMNLP] **A Nil-Aware Answer Extraction Framework for Question Answering**, [[paper]](https://www.aclweb.org/anthology/D18-1456.pdf), [[bibtex]](https://www.aclweb.org/anthology/D18-1456.bib), sources: [[nusnlp/namanda]](https://github.com/nusnlp/namanda).
- [2018 ICLR] **Ask the Right Questions: Active Question Reformulation with Reinforcement Learning**, [[paper]](https://openreview.net/pdf?id=S1CChZ-CZ), [[bibtex]](/Bibtex/Ask%20the%20Right%20Questions%20-%20Active%20Question%20Reformulation%20with%20Reinforcement%20Learning.bib), sources: [[google/active-qa]](https://github.com/google/active-qa).
- [2019 ACL] **MULTIQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension**, [[paper]](https://www.aclweb.org/anthology/P19-1485.pdf), [[bibtex]](/Bibtex/MULTIQA%20-%20An%20Empirical%20Investigation%20of%20Generalization%20and%20Transfer%20in%20Reading%20Comprehension.bib), sources: [[alontalmor/MultiQA]](https://github.com/alontalmor/MultiQA).
- [2019 ACL] **Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension**, [[paper]](https://www.aclweb.org/anthology/P19-1218.pdf), [[bibtex]](https://www.aclweb.org/anthology/P19-1218.bib).
- [2019 AAAI] **Read + Verify: Machine Reading Comprehension with Unanswerable Questions**, [[paper]](https://arxiv.org/pdf/1808.05759.pdf), [[bibtex]](/Bibtex/Read%20+%20Verify%20-%20Machine%20Reading%20Comprehension%20with%20Unanswerable%20Questions.bib).
- [2019 ArXiv] **What does BERT Learn from Multiple-Choice Reading Comprehension Datasets?**, [[paper]](https://arxiv.org/pdf/1910.12391.pdf), [[bibtex]](https://scholar.googleusercontent.com/scholar.bib?q=info:u9nIuElO3DUJ:scholar.google.com/&output=citation&scisdr=CgWaFqqJENWowxBev7I:AAGBfm0AAAAAXudbp7LxNdjieCkj4YfW-axP2-cmNB3r&scisig=AAGBfm0AAAAAXudbpwJHRWDHFVn52UT2M4EHM77622D-&scisf=4&ct=citation&cd=-1&hl=en).
- [2020 AAAI] **MMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1910.00458.pdf), [[bibtex]](/Bibtex/MMM%20-%20Multi-stage%20Multi-task%20Learning%20for%20Multi-choice%20Reading%20Comprehension.bib).
- [2020 AAAI] **Unsupervised Domain Adaptation on Reading Comprehension**, [[paper]](https://arxiv.org/pdf/1911.06137.pdf), [[bibtex]](/Bibtex/Unsupervised%20Domain%20Adaptation%20on%20Reading%20Comprehension.bib), sources: [[caoyu1991/CASe]](https://github.com/caoyu1991/CASe).
- [2020 ICLR] **Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention**, [[paper]](https://openreview.net/pdf?id=r1eIiCNYwS), [[bibtex]](/Bibtex/Transformer-XH%20-%20Multi-Evidence%20Reasoning%20with%20Extra%20Hop%20Attention.bib), sources: [[microsoft/Transformer-XH]](https://github.com/microsoft/Transformer-XH).
- [2020 ACL] **Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering**, [[paper]](https://www.aclweb.org/anthology/2020.acl-main.654.pdf), [[bibtex]](https://www.aclweb.org/anthology/2020.acl-main.654.bib).
