# Other Research Works

- Self-supervised Learning resources: [[jason718/awesome-self-supervised-learning]](https://github.com/jason718/awesome-self-supervised-learning).
- Incremental Learning resources: [[xialeiliu/Awesome-Incremental-Learning]](https://github.com/xialeiliu/Awesome-Incremental-Learning).

## Error Correcting Output Code (ECOC)
- [2016 ArXiv] **N-ary Error Correcting Coding Scheme**, [[paper]](https://arxiv.org/pdf/1603.05850.pdf), [[bibtex]](/Bibtex/N-ary%20Error%20Correcting%20Coding%20Scheme.bib).
- [2018 JIIS] **Experimental Validation for N-ary Error Correcting Output Codes for Ensemble Learning of Deep Neural Networks**, [[paper]](/Documents/Papers/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.pdf), [[bibtex]](/Bibtex/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.bib).

## Label Embeddings
- [2018 ACL] **Multi-Task Label Embedding for Text Classification**, [[paper]](https://www.aclweb.org/anthology/D18-1484), [[bibtex]](/Bibtex/Multi-Task%20Label%20Embedding%20for%20Text%20Classification.bib), [[blog]](https://www.jianshu.com/p/4bbe061f0acd).
- [2018 ACL] **Joint Embedding of Words and Labels for Text Classification**, [[paper]](https://www.aclweb.org/anthology/P18-1216), [[bibtex]](/Bibtex/Joint%20Embedding%20of%20Words%20and%20Labels%20for%20Text%20Classification.bib), [[poster]](https://www.aclweb.org/anthology/attachments/P18-1216.Poster.pdf), sources: [[guoyinwang/LEAM]](https://github.com/guoyinwang/LEAM).
- [2018 TACL] **GILE: A Generalized Input-Label Embedding for Text Classification**, [[paper]](https://www.aclweb.org/anthology/Q19-1009), [[bibtex]](/Bibtex/GILE%20-%20A%20Generalized%20Input-Label%20Embedding%20for%20Text%20Classification.bib), sources: [[idiap/gile]](https://github.com/idiap/gile).

## Recommendation System
- [2018 ArXiv] **Next Item Recommendation with Self-Attention**, [[paper]](https://arxiv.org/pdf/1808.06414.pdf), [[bibtex]](/Bibtex/Next%20Item%20Recommendation%20with%20Self-Attention.bib).
- [2018 ICDM] **Self-Attentive Sequential Recommendation**, [[paper]](https://arxiv.org/pdf/1808.09781.pdf), [[bibtex]](/Bibtex/Self-Attentive%20Sequential%20Recommendation.bib), sources: [[kang205/SASRec]](https://github.com/kang205/SASRec).
- [2018 KDD] **Multi-Pointer Co-Attention Networks for Recommendation**, [[paper]](https://arxiv.org/pdf/1801.09251.pdf), [[bibtex]](/Bibtex/Multi-Pointer%20Co-Attention%20Networks%20for%20Recommendation.bib), sources: [[vanzytay/KDD2018_MPCN]](https://github.com/vanzytay/KDD2018_MPCN).
- [2019 RecSys] **Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches**, [[paper]](https://arxiv.org/pdf/1907.06902.pdf), [[bibtex]](/Bibtex/Are%20We%20Really%20Making%20Much%20Progress%20A%20Worrying%20Analysis%20of%20Recent%20Neural%20Recommendation%20Approaches.bib), sources: [[MaurizioFD/RecSys2019_DeepLearning_Evaluation]](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation).

## Incremental Learning / Lifelong learning
- GitHub page: [[xialeiliu/Awesome-Incremental-Learning]](https://github.com/xialeiliu/Awesome-Incremental-Learning).
- [2016 PNAS] **Overcoming Catastrophic Forgetting in Neural Networks**, [[paper]](https://www.pnas.org/content/pnas/114/13/3521.full.pdf), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20in%20Neural%20Networks.bib), [[supplementary]](https://www.pnas.org/content/pnas/suppl/2017/03/14/1611835114.DCSupplemental/pnas.201611835SI.pdf), sources: [[ariseff/overcoming-catastrophic]](https://github.com/ariseff/overcoming-catastrophic), [[AntiAegis/Overcoming-Catastrophic-Forgetting]](https://github.com/AntiAegis/Overcoming-Catastrophic-Forgetting).
- [2017 NIPS] **Overcoming Catastrophic Forgetting by Incremental Moment Matching**, [[paper]](https://papers.nips.cc/paper/7051-overcoming-catastrophic-forgetting-by-incremental-moment-matching.pdf), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20by%20Incremental%20Moment%20Matching.bib), sources: [[btjhjeon/IMM_tensorflow]](https://github.com/btjhjeon/IMM_tensorflow).
- [2018 ArXiv] **Overcoming Catastrophic Forgetting by Soft Parameter Pruning**, [[paper]](https://arxiv.org/pdf/1812.01640.pdf), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20by%20Soft%20Parameter%20Pruning.bib), sources: [[lehaifeng/Learning_by_memory]](https://github.com/lehaifeng/Learning_by_memory).
- [2018 ICML] **Overcoming Catastrophic Forgetting with Hard Attention to the Task**, [[paper]](http://proceedings.mlr.press/v80/serra18a/serra18a.pdf), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20with%20Hard%20Attention%20to%20the%20Task.bib), [[supplementary]](http://proceedings.mlr.press/v80/serra18a/serra18a-supp.pdf), sources: [[joansj/hat]](https://github.com/joansj/hat), 
- [2019 ICLR] **Overcoming Catastrophic Forgetting for Continual Learning via Model Adaptation**, [[paper]](https://openreview.net/pdf?id=ryGvcoA5YX), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20for%20Continual%20Learning%20via%20Model%20Adaptation.bib), sources: [[morning-dews/PGMA_tensorflow]](https://github.com/morning-dews/PGMA_tensorflow).
- [2019 NAACL] **Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation**, [[paper]](https://www.aclweb.org/anthology/N19-1209), [[bibtex]](/Bibtex/Overcoming%20Catastrophic%20Forgetting%20During%20Domain%20Adaptation%20of%20Neural%20Machine%20Translation.bib).
- [2019 ICML] **Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting**, [[paper]](http://proceedings.mlr.press/v97/li19m/li19m.pdf), [[bibtex]](/Bibtex/Learn%20to%20Grow%20-%20A%20Continual%20Structure%20Learning%20Framework%20for%20Overcoming%20Catastrophic%20Forgetting.bib), [[supplementary]](http://proceedings.mlr.press/v97/li19m/li19m-supp.pdf), sources: [[xilaili/LearnToGrow]](https://github.com/xilaili/LearnToGrow).

## Network Architecture Search
- [2019 ICLR] **DARTS: Differentiable Architecture Search**, [[paper]](https://openreview.net/pdf?id=S1eYHoC5FX), [[bibtex]](/Bibtex/DARTS%20-%20Differentiable%20Architecture%20Search.bib), [[homepage]](https://ai.google/research/pubs/pub47800/), sources: [[quark0/darts]](https://github.com/quark0/darts).
- [2019 CVPR] **Searching for A Robust Neural Architecture in Four GPU Hours**, [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Searching%20for%20A%20Robust%20Neural%20Architecture%20in%20Four%20GPU%20Hours.bib), sources: [[D-X-Y/GDAS]](https://github.com/D-X-Y/GDAS).

## Network Structure Pruning
- [2019 ICML] **EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis**, [[paper]](http://proceedings.mlr.press/v97/wang19g/wang19g.pdf), [[bibtex]](/Bibtex/EigenDamage%20-%20Structured%20Pruning%20in%20the%20Kronecker-Factored%20Eigenbasis.bib), [[supplementary]](http://proceedings.mlr.press/v97/wang19g/wang19g-supp.pdf), sources: [[alecwangcq/EigenDamage-Pytorch]](https://github.com/alecwangcq/EigenDamage-Pytorch).

## Neural Network Optimization
- [2009 ICML] **Curriculum Learning**, [[paper]](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf).
- [2010 AISTATS] **Understanding the difficulty of training deep feedforward neural networks**, [[paper]](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf).
- [2011 ICML] **On Optimization Methods for Deep Learning**, [[paper]](http://ai.stanford.edu/~quocle/LeNgiCoaLahProNg11.pdf), [[homepage]](http://www.andrewng.org/portfolio/on-optimization-methods-for-deep-learning/).
- [2013 ICML] **Maxout Networks**, [[paper]](https://arxiv.org/pdf/1302.4389.pdf), sources: [[philipperemy/tensorflow-maxout]](https://github.com/philipperemy/tensorflow-maxout).
- [2014 JMLR] **Dropout: A Simple Way to Prevent Neural Networks from Overfitting**, [[paper]](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf).
- [2015 ICCV] **Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification**, [[paper]](https://arxiv.org/abs/1502.01852), [[Kaiming He's homepage]](http://kaiminghe.com), sources: [[nutszebra/prelu_net]](https://github.com/nutszebra/prelu_net).
- [2015 ICML] **Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**, [[paper]](https://arxiv.org/abs/1502.03167), sources: [[IsaacChanghau/AmusingPythonCodes/batch_normalization]](https://github.com/IsaacChanghau/AmusingPythonCodes/tree/master/batch_normalization), [[tomokishii/mnist_cnn_bn.py]](https://gist.github.com/tomokishii/0ce3bdac1588b5cca9fa5fbdf6e1c412).
- [2016 ICLR] **Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)**, [[paper]](https://arxiv.org/abs/1511.07289).
- [2016 ArXiv] **An overview of gradient descent optimization algorithms**, [[paper]](https://arxiv.org/abs/1609.04747), [[slides]](https://qdata.github.io/deep2Read//talks/20171031-Ceyer.pdf).
- [2016 ArXiv] **Layer Normalization**, [[paper]](https://arxiv.org/abs/1607.06450), sources: [[ryankiros/layer-norm]](https://github.com/ryankiros/layer-norm), [[pbhatia243/tf-layer-norm]](https://github.com/pbhatia243/tf-layer-norm), [[NickShahML/tensorflow_with_latest_papers]](https://github.com/NickShahML/tensorflow_with_latest_papers).
- [2016 ICLR] **Incorporating Nesterov Momentum into Adam**, [[paper]](https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ).
- [2016 ECCV] **Layer Dropout: Deep Networks with Stochastic Depth**, [[paper]](https://arxiv.org/pdf/1603.09382.pdf), [[poster]](http://www.eccv2016.org/files/posters/S-3A-08.pdf), sources: [[yueatsprograms/Stochastic_Depth]](https://github.com/yueatsprograms/Stochastic_Depth), [[samjabrahams/stochastic-depth-tensorflow]](https://github.com/samjabrahams/stochastic-depth-tensorflow).
- [2017 NIPS] **Self-Normalizing Neural Networks**, [[paper]](https://arxiv.org/abs/1706.02515), sources: [[IsaacChanghau/AmusingPythonCodes/selu_activation_visualization]](https://github.com/IsaacChanghau/AmusingPythonCodes/tree/master/selu_activation_visualization), [[shaohua0116/Activation-Visualization-Histogram]](https://github.com/shaohua0116/Activation-Visualization-Histogram), [[bioinf-jku/SNNs]](https://github.com/bioinf-jku/SNNs), [[IsaacChanghau/AmusingPythonCodes/snns]](https://github.com/IsaacChanghau/AmusingPythonCodes/tree/master/snns).
- [2017 ICLR] **Recurrent Batch Normalization**, [[paper]](https://arxiv.org/abs/1603.09025), sources: [[cooijmanstim/recurrent-batch-normalization]](https://github.com/cooijmanstim/recurrent-batch-normalization), [[jihunchoi/recurrent-batch-normalization-pytorch]](https://github.com/jihunchoi/recurrent-batch-normalization-pytorch).
- [2018 AAAI] **Adversarial Dropout for Supervised and Semi-Supervised Learning**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16322/16639), [[bibtex]](/Bibtex/Adversarial%20Dropout%20for%20Supervised%20and%20Semi-Supervised%20Learning.bib), sources: [[sungraepark/Adversarial-Dropout]](https://github.com/sungraepark/Adversarial-Dropout).
- [2019 NeurIPS] **Understanding and Improving Layer Normalization**, [[paper]](https://papers.nips.cc/paper/2019/file/2f4fe03d77724a7217006e5d16728874-Paper.pdf), [[bibtex]](/Bibtex/Understanding%20and%20Improving%20Layer%20Normalization.bib), sources: [[lancopku/AdaNorm]](https://github.com/lancopku/AdaNorm).
- [2020 ArXiv] **On Layer Normalization in the Transformer Architecture**, [[paper]](https://arxiv.org/pdf/2002.04745.pdf), [[bibtex]](/Bibtex/On%20Layer%20Normalization%20in%20the%20Transformer%20Architecture.bib).

## Categorical Reparameterization and Its Applications
- [2017 ICLR] **Categorical Reparameterization with Gumbel-SoftMax**, [[paper]](https://openreview.net/pdf?id=rkE3y85ee), [[bibtex]](/Bibtex/Categorical%20Reparameterization%20with%20Gumbel-SoftMax.bib), sources: [[ericjang/gumbel-softmax]](https://github.com/ericjang/gumbel-softmax).
- [2017 ICLR] **The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables**, [[paper]](http://www.stats.ox.ac.uk/~cmaddis/pubs/concrete.pdf), [[bibtex]](/Bibtex/The%20Concrete%20Distribution%20-%20A%20Continuous%20Relaxation%20of%20Discrete%20Random%20Variables.bib), sources: [[pytorch/relaxed_categorical]](https://github.com/pytorch/pytorch/blob/master/torch/distributions/relaxed_categorical.py).
- [2018 ICLR] **Learning Latent Permutations with Gumbel-Sinkhorn Networks**, [[paper]](https://openreview.net/pdf?id=Byt3oJ-0W), [[bibtex]](/Bibtex/Learning%20Latent%20Permutations%20with%20Gumbel-Sinkhorn%20Networks.bib), sources: [[google/gumbel_sinkhorn]](https://github.com/google/gumbel_sinkhorn), [[HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch]](https://github.com/HeddaCohenIndelman/Learning-Gumbel-Sinkhorn-Permutations-w-Pytorch).
- [2018 IJCAI] **Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling**, [[paper]](https://www.ijcai.org/Proceedings/2018/0604.pdf), [[bibtex]](/Bibtex/Reinforced%20Self-Attention%20Network%20-%20a%20Hybrid%20of%20Hard%20and%20Soft%20Attention%20for%20Sequence%20Modeling.bib).
- [2018 TCSVT] **Sharp Attention Network via Adaptive Sampling for Person Re-identification**, [[paper]](https://arxiv.org/pdf/1805.02336.pdf), [[bibtex]](/Bibtex/Sharp%20Attention%20Network%20via%20Adaptive%20Sampling%20for%20Person%20Re-identification.bib).
- [2019 CVPR] **Modeling Point Clouds with Self-Attention and Gumbel Subset Sampling**, [[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Modeling_Point_Clouds_With_Self-Attention_and_Gumbel_Subset_Sampling_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Modeling%20Point%20Clouds%20with%20Self-Attention%20and%20Gumbel%20Subset%20Sampling.bib).
- [2019 CVPR] **Searching for A Robust Neural Architecture in Four GPU Hours**, [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Searching%20for%20A%20Robust%20Neural%20Architecture%20in%20Four%20GPU%20Hours.bib), sources: [[D-X-Y/GDAS]](https://github.com/D-X-Y/GDAS).
- [2020 ACL] **How Does Selective Mechanism Improve Self-Attention Networks?**, [[paper]](https://www.aclweb.org/anthology/2020.acl-main.269.pdf), [[bibtex]](/Bibtex/How%20Does%20Selective%20Mechanism%20Improve%20Self-Attention%20Networks.bib), sources: [[xwgeng/SSAN]](https://github.com/xwgeng/SSAN)。

## Others
- [2013 ICML] **Deep Canonical Correlation Analysis**, [[paper]](http://proceedings.mlr.press/v28/andrew13.pdf), [[bibtex]](/Bibtex/Deep%20Canonical%20Correlation%20Analysis.bib), sources: [[VahidooX/DeepCCA]](https://github.com/VahidooX/DeepCCA), [[DTaoo/DCCA]](https://github.com/DTaoo/DCCA), [[msamribeiro/deep-cca]](https://github.com/msamribeiro/deep-cca), [[wangxu-scu/DeepCCA]](https://github.com/wangxu-scu/DeepCCA).
- [2014 EACL] **CCA: Improving Vector Space Word Representations Using Multilingual Correlation**, [[paper]](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi-mLO_-o7bAhVKrY8KHQIDBREQFggmMAA&url=http%3A%2F%2Fanthology.aclweb.org%2FE%2FE14%2FE14-1049.pdf&usg=AOvVaw0C2reHtfMC13b2L5FP6z1F).
- [2016 NIPS] **Domain Separation Networks**, [[paper]](https://papers.nips.cc/paper/6254-domain-separation-networks.pdf), [[bibtex]](/Bibtex/Domain%20Separation%20Networks.bib), sources: [[tensorflow/models/research/domain_adaptation]](https://github.com/tensorflow/models/tree/master/research/domain_adaptation), [[fungtion/DSN]](https://github.com/fungtion/DSN), [[wj926/DomainSeparationNetworks]](https://github.com/wj926/DomainSeparationNetworks).
- [2017 TIML] **Efficient Methods and Hardware for Deep Learning**, [[Ph.D Thesis]](https://stacks.stanford.edu/file/druid:qf934gh3708/EFFICIENT%20METHODS%20AND%20HARDWARE%20FOR%20DEEP%20LEARNING-augmented.pdf), [[Song Han's homepage]](https://mtlsites.mit.edu/songhan/), [[slides]](https://platformlab.stanford.edu/Seminar%20Talks/retreat-2017/Song%20Han.pdf).
- [2017 NIPS] **SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability**, [[paper]](https://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability.pdf), sources: [[google/svcca]](https://github.com/google/svcca).
- [2017 ArXiv] **One Model To Learn Them All**, [[paper]](https://arxiv.org/abs/1706.05137.pdf), [[blog]](https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/).
- [2017 ArXiv] **An Overview of Multi-Task Learning in Deep Neural Networks**, [[paper]](https://arxiv.org/pdf/1706.05098.pdf), [[bibtex]](/Bibtex/An%20Overview%20of%20Multi-Task%20Learning%20in%20Deep%20Neural%20Networks.bib).
- [2017 PNAS] **Robust Continuous Clustering**, [[paper]](http://vladlen.info/papers/RCC-with-supplement.pdf), [[bibtex]](/Bibtex/Robust%20Continuous%20Clustering.bib), sources: [[sohilas/robust-continuous-clustering]](https://bitbucket.org/sohilas/robust-continuous-clustering/overview), [[yhenon/pyrcc]](https://github.com/yhenon/pyrcc), [[shahsohil/DCC]](https://github.com/shahsohil/DCC).
- [2018 ArXiv] **Tunneling Neural Perception and Logic Reasoning through Abductive Learning**, [[paper]](https://arxiv.org/pdf/1802.01173.pdf).
- [2018 ArXiv] **Representation Learning with Contrastive Predictive Coding**, [[paper]](https://arxiv.org/pdf/1807.03748.pdf), [[bibtex]](https://scholar.googleusercontent.com/scholar.bib?q=info:nXIm5kRJCzIJ:scholar.google.com/&output=citation&scisdr=CgWaFqqJELnwmeJ-gKc:AAGBfm0AAAAAXxp7mKcOgUwSpXUG81jJE1eaqKav6z-m&scisig=AAGBfm0AAAAAXxp7mMs0nNBeQVemQAoEzUdMqPZNt3Q1&scisf=4&ct=citation&cd=-1&hl=en), sources: [[davidtellez/contrastive-predictive-coding]](https://github.com/davidtellez/contrastive-predictive-coding), [[flrngel/cpc-tensorflow]](https://github.com/flrngel/cpc-tensorflow), [[jefflai108/Contrastive-Predictive-Coding-PyTorch]](https://github.com/jefflai108/Contrastive-Predictive-Coding-PyTorch).
- [2018 AAAI] **Reliable Multi-View Clustering**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16245/16686), [[bibtex]](/Bibtex/Reliable%20Multi-View%20Clustering.bib).
- [2018 AAAI] **SC2Net: Sparse LSTMs for Sparse Coding**, [[paper]](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16822/16773), [[bibtex]](/Bibtex/SC2Net%20-%20Sparse%20LSTMs%20for%20Sparse%20Coding.bib), sources: [[joeyzhouty/sc2net]](https://github.com/joeyzhouty/sc2net).
- [2018 CVPR] **Squeeze-and-Excitation Networks**, [[paper]](https://zpascal.net/cvpr2018/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf), [[bibtex]](/Bibtex/Squeeze-and-Excitation%20Networks.bib), sources: [[hujie-frank/SENet]](https://github.com/hujie-frank/SENet).
- [2019 ArXiv] **Implicit Generation and Generalization in Energy-Based Models**, [[paper]](https://arxiv.org/pdf/1903.08689.pdf), [[bibtex]](/Bibtex/Implicit%20Generation%20and%20Generalization%20in%20Energy-Based%20Models.bib), [[homepage]](https://sites.google.com/view/igebm), [[blog]](https://openai.com/blog/energy-based-models/), [[ext. readings]](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf), sources: [[openai/ebm_code_release]](https://github.com/openai/ebm_code_release), [[rosinality/igebm-pytorch]](https://github.com/rosinality/igebm-pytorch).
- [2019 SIGIR] **Finding Camouflaged Needle in a Haystack? Pornographic Products Detection via Berrypicking Tree Model**, [[paper]](/Documents/Papers/Finding%20Camouflaged%20Needle%20in%20a%20Haystack%20Pornographic%20Products%20Detection%20via%20Berrypicking%20Tree%20Model.pdf), [[bibtex]](/Bibtex/Finding%20Camouflaged%20Needle%20in%20a%20Haystack%20Pornographic%20Products%20Detection%20via%20Berrypicking%20Tree%20Model.bib), [[slides]](https://sigir.org/sigir2019/slides/10.1145-3331184.3331197.pdf), sources: [[GuoxiuHe/BIRD]](https://github.com/GuoxiuHe/BIRD).
- [2019 NeurIPS] **PyTorch: An Imperative Style, High-Performance Deep Learning Library**, [[paper]](https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf), [[bibtex]](/Bibtex/PyTorch%20-%20An%20Imperative%20Style%20High-Performance%20Deep%20Learning%20Library.bib).
